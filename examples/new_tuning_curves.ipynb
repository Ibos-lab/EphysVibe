{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from ephysvibe.trials.spikes import firing_rate,sp_constants\n",
    "# from ephysvibe.trials import select_trials\n",
    "from ephysvibe.spike_sorting import config\n",
    "from ephysvibe.task import def_task,task_constants\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "from ephysvibe.structures.spike_data import SpikeData\n",
    "from ephysvibe.structures.bhv_data import BhvData\n",
    "from ephysvibe.analysis import circular_stats\n",
    "import os \n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Def functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data:np.ndarray,win:int,step:int=1)-> np.ndarray:\n",
    "    d_shape=data.shape\n",
    "    count = 0\n",
    "    if len(d_shape) == 3:\n",
    "        d_avg = np.zeros((d_shape[0],d_shape[1],int(np.floor(d_shape[2]/step))))\n",
    "        for i_step in np.arange(0,d_shape[2]-win,step):\n",
    "            d_avg[:,:,count] = np.mean(data[:,:,i_step:i_step+win],axis=2)\n",
    "            count +=1\n",
    "    if len(d_shape) == 2:\n",
    "        d_avg = np.zeros((d_shape[0],int(np.floor(d_shape[1]/step))))\n",
    "        for i_step in np.arange(0,d_shape[1]-win,step):\n",
    "            d_avg[:,count] = np.mean(data[:,i_step:i_step+win],axis=1)\n",
    "            count +=1\n",
    "    if len(d_shape) == 1:\n",
    "        d_avg = np.zeros((int(np.floor(d_shape[0]/step))))\n",
    "        for i_step in np.arange(0,d_shape[0]-win,step):\n",
    "            d_avg[count] = np.mean(data[i_step:i_step+win],axis=0)\n",
    "            count +=1\n",
    "    return d_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_variables(data:SpikeData,bhv:BhvData,in_out:str='in'):\n",
    "    # Select trials (correct and DMTS task) and create task frame\n",
    "    trial_idx = np.where(np.logical_and(data.trial_error == 0, data.block == 1))[0]\n",
    "\n",
    "    if np.any(np.isnan(data.neuron_cond)):\n",
    "        neuron_cond = np.ones(len(data.clustersgroup))\n",
    "    else:\n",
    "        neuron_cond=data.neuron_cond\n",
    "    task = def_task.create_task_frame(\n",
    "        condition=bhv.condition[trial_idx],\n",
    "        test_stimuli=bhv.test_stimuli[trial_idx],\n",
    "        samples_cond=task_constants.SAMPLES_COND,\n",
    "        neuron_cond = neuron_cond,\n",
    "    )\n",
    "    task = task[task['in_out']==in_out]\n",
    "    return task, trial_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_match(test_stimuli,code):\n",
    "    code = (code-1).astype(int)\n",
    "    tests_shape=test_stimuli.shape\n",
    "    test_stimuli = np.concatenate([test_stimuli,np.ones((tests_shape[0],1))],axis=1)\n",
    "    test_stimuli[np.arange(tests_shape[0]),code] =  np.nan\n",
    "    test_stimuli = test_stimuli[:,:tests_shape[1]]\n",
    "    return test_stimuli.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp_feature(sp_samples_samp,test_stimuli_samp,code_samples_samp,color_orient,stim_num):\n",
    "    all_sp_tests=[]\n",
    "    st = 0\n",
    "    end =1\n",
    "    if color_orient == 1:\n",
    "        st = 1\n",
    "        end =2\n",
    "    for i_num,i_stim in enumerate(stim_num):\n",
    "        i_trial, i_test = np.where(np.char.find(test_stimuli_samp,i_stim,start=st, end=end)==color_orient)\n",
    "        tests_on = code_samples_samp[i_trial,2*i_test+6].astype(int)\n",
    "        sp_stim = sp_samples_samp[i_trial]\n",
    "        sp_tests = SpikeData.indep_roll(sp_stim, -tests_on, axis=1)[:, 0:550]\n",
    "        if np.isnan(np.sum(sp_tests)):\n",
    "            raise ValueError('nan values')\n",
    "        all_sp_tests.append(sp_tests)\n",
    "    return all_sp_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Permutation test\n",
    "def permutation_test(mean_select,mean_null):\n",
    "    radius = mean_select[:,0]\n",
    "    angle =  mean_select[:,1]\n",
    "    X = (np.array(radius) * np.cos(angle))\n",
    "    Y = (np.array(radius) * np.sin(angle))\n",
    "    ampl_dir_vector = np.sqrt(X**2+Y**2)\n",
    "    radius = mean_null[:,0]\n",
    "    angle =  mean_null[:,1]\n",
    "    X = (np.array(radius) * np.cos(angle))\n",
    "    Y = (np.array(radius) * np.sin(angle))\n",
    "    ampl_null_vector = np.sqrt(X**2+Y**2)\n",
    "    diff=[]\n",
    "    for i in range(len(ampl_dir_vector)):\n",
    "        # rotate vecto to compare all values with the null vector\n",
    "        shift = np.concatenate([ampl_dir_vector[i:],ampl_dir_vector[:i]])\n",
    "        diff.append(shift-ampl_null_vector)\n",
    "    diff=np.concatenate(diff)\n",
    "    p_value = np.sum(diff<0)/len(diff)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_vector_from_samples(trials_fr,min_n_trials,seed:int=1,n_iterations:int=1000):\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    it_seed = rng.integers(low=1, high=10000, size=n_iterations, dtype=int)\n",
    "    stim_num=['1','2','3','4','5','6','7','8']\n",
    "    stim_angle = np.array([0,45,90,135,180,225,270,315]) * np.pi/180\n",
    "    mean_select=[]\n",
    "\n",
    "    for n_it in range(n_iterations):\n",
    "        all_sample1 = []\n",
    "        \n",
    "        np.random.seed(it_seed[n_it]) \n",
    "        for i_num,i_stim in enumerate(stim_num):\n",
    "            all_sample1.append(np.random.choice(trials_fr[i_num], size=min_n_trials[i_num], replace=False, p=None))\n",
    "        all_sample1 = np.concatenate(all_sample1)\n",
    "       \n",
    "        mean_resp = np.zeros((8,2))\n",
    "        for i_num,i_stim in enumerate(stim_num):\n",
    "            fr = np.random.choice(all_sample1, size=min_n_trials[i_num], replace=True, p=None)\n",
    "\n",
    "            mean_resp[i_num] = circular_stats.mean_vector(fr, [stim_angle[i_num]]*len(fr))\n",
    "        mean_select.append(circular_stats.mean_vector(mean_resp[:,0], mean_resp[:,1]) )\n",
    "    mean_select=np.array(mean_select)\n",
    "    return mean_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_rand_trials_from_samples(trials_fr,min_n_trials,seed:int=1,n_iterations:int=1000):\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    it_seed = rng.integers(low=1, high=10000, size=n_iterations, dtype=int)\n",
    "    stim_num=['1','2','3','4','5','6','7','8']\n",
    "    stim_angle = np.array([0,45,90,135,180,225,270,315]) * np.pi/180\n",
    "    mean_select=[]\n",
    "    for n_it in range(n_iterations):\n",
    "        np.random.seed(it_seed[n_it]) \n",
    "        mean_resp = np.zeros((8,2))\n",
    "        for i_num,i_stim in enumerate(stim_num):\n",
    "            fr = np.random.choice(trials_fr[i_num], size=min_n_trials[i_num], replace=True, p=None)\n",
    "            mean_resp[i_num] = circular_stats.mean_vector(fr, [stim_angle[i_num]]*len(fr))\n",
    "        mean_select.append(circular_stats.mean_vector(mean_resp[:,0], mean_resp[:,1]) )\n",
    "    mean_select=np.array(mean_select)\n",
    "    return mean_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"/envau/work/invibe/USERS/IBOS/code/flow/paths_bhv_lip.txt\", \"r\")\n",
    "lines_bhv = file1.readlines()\n",
    "file1 = open(\"/envau/work/invibe/USERS/IBOS/code/flow/paths_sp_lip.txt\", \"r\")\n",
    "lines_sp = file1.readlines()\n",
    "# load all  files\n",
    "paths_bhv,paths_sp=[],[]\n",
    "for line in lines_bhv:\n",
    "    paths_bhv.append(line.strip())\n",
    "for line in lines_sp:\n",
    "    paths_sp.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "orient = 0 \n",
    "color = 1\n",
    "stim_num=['1','2','3','4','5','6','7','8']\n",
    "sample=[\"o1_c1\",\"o5_c1\",\"o1_c5\",\"o5_c5\"]\n",
    "palette = plt.get_cmap('hsv',64)\n",
    "len_t = 450\n",
    "n_iterations = 1000\n",
    "win=100\n",
    "step=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-24_10-43-44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43559/3123404539.py:7: RuntimeWarning: invalid value encountered in cast\n",
      "  return test_stimuli.astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-28_10-15-02\n",
      "5\n",
      "0.806742\n",
      "0.61924\n",
      "2023-03-01_10-18-38\n",
      "2023-03-03_10-59-32\n",
      "2023-03-06_10-32-51\n",
      "0\n",
      "0.245016\n",
      "0.072801\n",
      "3\n",
      "0.765489\n",
      "0.45627700000000004\n",
      "5\n",
      "0.30971800000000005\n",
      "0.73105\n",
      "2023-03-07_10-14-11\n",
      "0\n",
      "0.535926\n",
      "0.10825200000000001\n",
      "1\n",
      "0.26837\n",
      "0.438875\n",
      "2\n",
      "0.632952\n",
      "0.35619999999999996\n",
      "2023-03-09_10-35-09\n",
      "2023-03-10_10-30-26\n",
      "3\n",
      "0.411052\n",
      "0.808952\n",
      "2023-03-14_10-33-51\n",
      "2023-03-16_10-20-01\n",
      "2023-03-17_10-11-51\n",
      "2\n",
      "0.797627\n",
      "0.15424800000000005\n",
      "9\n",
      "0.028000000000000025\n",
      "0.797257\n",
      "2023-03-20_10-39-08\n",
      "2\n",
      "0.844504\n",
      "0.948214\n",
      "3\n",
      "0.28404300000000005\n",
      "0.326384\n",
      "5\n",
      "0.82005\n",
      "0.6583220000000001\n",
      "10\n",
      "0.875184\n",
      "0.311072\n",
      "2023-03-21_10-40-02\n",
      "1\n",
      "0.924053\n",
      "0.453029\n",
      "2023-03-22_10-34-47\n",
      "2023-03-30_10-36-53\n",
      "3\n",
      "0.03600000000000003\n",
      "0.761394\n",
      "2023-10-06_10-38-57\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 1 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/INT/losada.c/Documents/codes/EphysVibe/examples/new_tuning_curves.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/INT/losada.c/Documents/codes/EphysVibe/examples/new_tuning_curves.ipynb#X21sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m sp_samples_samp \u001b[39m=\u001b[39m sp_samples[trials]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/INT/losada.c/Documents/codes/EphysVibe/examples/new_tuning_curves.ipynb#X21sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m code \u001b[39m=\u001b[39m task_sample[\u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/INT/losada.c/Documents/codes/EphysVibe/examples/new_tuning_curves.ipynb#X21sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m test_stimuli_samp \u001b[39m=\u001b[39m delete_match(test_stimuli_samp,code)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/INT/losada.c/Documents/codes/EphysVibe/examples/new_tuning_curves.ipynb#X21sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# use only the first n test stimuli presentations\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/INT/losada.c/Documents/codes/EphysVibe/examples/new_tuning_curves.ipynb#X21sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m n_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfull(test_stimuli_samp\u001b[39m.\u001b[39mshape,np\u001b[39m.\u001b[39mnan)\n",
      "\u001b[1;32m/home/INT/losada.c/Documents/codes/EphysVibe/examples/new_tuning_curves.ipynb Cell 13\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/INT/losada.c/Documents/codes/EphysVibe/examples/new_tuning_curves.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tests_shape\u001b[39m=\u001b[39mtest_stimuli\u001b[39m.\u001b[39mshape\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/INT/losada.c/Documents/codes/EphysVibe/examples/new_tuning_curves.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_stimuli \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([test_stimuli,np\u001b[39m.\u001b[39mones((tests_shape[\u001b[39m0\u001b[39m],\u001b[39m1\u001b[39m))],axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/INT/losada.c/Documents/codes/EphysVibe/examples/new_tuning_curves.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test_stimuli[np\u001b[39m.\u001b[39;49marange(tests_shape[\u001b[39m0\u001b[39;49m]),code] \u001b[39m=\u001b[39m  np\u001b[39m.\u001b[39mnan\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/INT/losada.c/Documents/codes/EphysVibe/examples/new_tuning_curves.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m test_stimuli \u001b[39m=\u001b[39m test_stimuli[:,:tests_shape[\u001b[39m1\u001b[39m]]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/INT/losada.c/Documents/codes/EphysVibe/examples/new_tuning_curves.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m test_stimuli\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for axis 1 with size 5"
     ]
    }
   ],
   "source": [
    "selectivity_info: Dict[str, list] = defaultdict(list)\n",
    "for n_bhv,n_sp in zip(paths_bhv[17:],paths_sp[17:]):\n",
    "    s_path = os.path.normpath(n_sp).split(os.sep)\n",
    "    date = s_path[-1][:19]\n",
    "    data = SpikeData.from_python_hdf5(n_sp)\n",
    "    bhv = BhvData.from_python_hdf5(n_bhv)\n",
    "    task_corr_in, idx_tr_corr_in = get_task_variables(data,bhv,in_out='in')\n",
    "    # Select data for the relevant trials\n",
    "    test_stimuli = bhv.test_stimuli[idx_tr_corr_in]\n",
    "    code_numbers = data.code_numbers[idx_tr_corr_in]\n",
    "    code_samples = data.code_samples[idx_tr_corr_in]\n",
    "    print(date)\n",
    "    for i_neuron in range(len(data.clustersgroup)):\n",
    "        sp_samples = data.sp_samples[idx_tr_corr_in,i_neuron]\n",
    "        task_one_neuron=task_corr_in[task_corr_in['i_neuron']==i_neuron]\n",
    "        task_trials = task_one_neuron['trial_idx'].values\n",
    "        # select trials with at least one spike\n",
    "        trial_idx = task_trials[np.nansum(sp_samples[task_trials],axis=1)>0]\n",
    "        task_fr = task_one_neuron[np.in1d(task_one_neuron['trial_idx'] , trial_idx)]\n",
    "\n",
    "        all_sample_feature = {\"o1_c1\":{\"color\":[],\"orientation\":[]},\"o1_c5\":{\"color\":[],\"orientation\":[]},\"o5_c1\":{\"color\":[],\"orientation\":[]},\"o5_c5\":{\"color\":[],\"orientation\":[]}}\n",
    "        for i,sample in enumerate([\"o1_c1\",\"o1_c5\",\"o5_c1\",\"o5_c5\"]):\n",
    "\n",
    "            task_sample = task_fr[task_fr['sample']==sample]\n",
    "            trials = task_sample['trial_idx'].values\n",
    "            test_stimuli_samp = test_stimuli[trials]\n",
    "            code_numbers_samp = code_numbers[trials]\n",
    "            code_samples_samp = code_samples[trials]\n",
    "            sp_samples_samp = sp_samples[trials]\n",
    "            \n",
    "            code = task_sample['code'].values\n",
    "            test_stimuli_samp = delete_match(test_stimuli_samp,code)\n",
    "            # use only the first n test stimuli presentations\n",
    "            n_test = np.full(test_stimuli_samp.shape,np.nan)\n",
    "            #n_test[:,:6] = test_stimuli_samp[:,:6]\n",
    "            n_test = test_stimuli_samp\n",
    "            n_test=n_test.astype(str)\n",
    "            \n",
    "            color_tests = get_sp_feature(sp_samples_samp,n_test,code_samples_samp,color_orient=color,stim_num=stim_num)\n",
    "            orient_tests = get_sp_feature(sp_samples_samp,n_test,code_samples_samp,color_orient=orient,stim_num=stim_num)\n",
    "\n",
    "            all_sample_feature[sample][\"color\"]= color_tests\n",
    "            all_sample_feature[sample][\"orientation\"]= orient_tests\n",
    "\n",
    "        o1_all = []\n",
    "        o5_all = []\n",
    "        c1_all = []\n",
    "        c5_all = []\n",
    "        for i in range(8):\n",
    "            o1_all.append(np.concatenate([all_sample_feature[\"o1_c1\"]['orientation'][i],all_sample_feature[\"o1_c5\"]['orientation'][i]],axis=0))\n",
    "            o5_all.append(np.concatenate([all_sample_feature[\"o5_c1\"]['orientation'][i],all_sample_feature[\"o5_c5\"]['orientation'][i]],axis=0))\n",
    "            c1_all.append(np.concatenate([all_sample_feature[\"o1_c1\"]['color'][i],all_sample_feature[\"o5_c1\"]['color'][i]],axis=0))\n",
    "            c5_all.append(np.concatenate([all_sample_feature[\"o1_c5\"]['color'][i],all_sample_feature[\"o5_c5\"]['color'][i]],axis=0))\n",
    "\n",
    "        o1_trial_avg,o5_trial_avg,c1_trial_avg,c5_trial_avg=[],[],[],[]\n",
    "        n_trials=[]\n",
    "        for i in range(8):\n",
    "            n_tr=[]\n",
    "            avg = o1_all[i][:,100:350].mean(axis=1)*1000\n",
    "            o1_trial_avg.append(avg)\n",
    "            n_tr.append(len(avg))\n",
    "            avg = o5_all[i][:,100:350].mean(axis=1)*1000\n",
    "            o5_trial_avg.append(avg)\n",
    "            n_tr.append(len(avg))\n",
    "            avg = c1_all[i][:,100:350].mean(axis=1)*1000\n",
    "            c1_trial_avg.append(avg)\n",
    "            n_tr.append(len(avg))\n",
    "            avg = c5_all[i][:,100:350].mean(axis=1)*1000\n",
    "            c5_trial_avg.append(avg)\n",
    "            n_tr.append(len(avg))\n",
    "            n_trials.append(n_tr)\n",
    "\n",
    "        min_n_trials = np.min(n_trials,axis=1).astype(int)\n",
    "        all_select = []\n",
    "        all_null=[]\n",
    "        all_p_value=[]\n",
    "        for trial_avg,feature in zip([o1_trial_avg,o5_trial_avg,c1_trial_avg,c5_trial_avg],['o1','o5','c1','c5']):\n",
    "\n",
    "            if np.sum(min_n_trials<3)>0 or np.concatenate(trial_avg).sum()==0:\n",
    "                p_value = np.nan\n",
    "                mean_null = np.zeros((2,2))\n",
    "                mean_select = np.zeros((2,2))\n",
    "            else:\n",
    "                mean_select = select_rand_trials_from_samples(trial_avg,min_n_trials,seed,n_iterations=1000)\n",
    "                mean_null = get_null_vector_from_samples(trial_avg,min_n_trials,seed,n_iterations=1000)\n",
    "                p_value = permutation_test(mean_select,mean_null)\n",
    "\n",
    "            all_select.append(mean_select)\n",
    "            all_null.append(mean_null)\n",
    "            all_p_value.append(p_value)\n",
    "            selectivity_info['date'] += [date]\n",
    "            selectivity_info['i_neuron'] += [i_neuron]\n",
    "            selectivity_info['neuron_type'] += [data.clustersgroup[i_neuron]]\n",
    "            selectivity_info['p_value'] += [p_value]\n",
    "            selectivity_info['sample1'] += [feature]\n",
    "\n",
    "        if np.sum(np.array(all_p_value)<0.05) >0: \n",
    "        # fig,((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2,figsize=(8,8),sharex=True,sharey=True,subplot_kw={'projection': 'polar'})\n",
    "        # for i,(ax, feature)in enumerate(zip([ax1,ax2,ax3,ax4],['o1','o5','c1','c5'])):\n",
    "        #     ax.set_rlabel_position(90)\n",
    "        #     ax.scatter(all_null[i][:,1],all_null[i][:,0],label='null')\n",
    "        #     ax.scatter(all_select[i][:,1],all_select[i][:,0],label='sample')\n",
    "        #     ax.set_title('%s    p_value: %f'%(feature,all_p_value[i]) )\n",
    "        # fig.suptitle('neuron: %d  date: %s'%(i_neuron,date),fontsize=7)\n",
    "        # plt.legend(loc='upper right', bbox_to_anchor=(0, 0), prop={'size': 8})\n",
    "\n",
    "            pref_dir_o1_0 = np.abs(0-all_select[0][:,1]*180/np.pi) \n",
    "            pref_dir_o5_0 = np.abs(0-all_select[1][:,1]*180/np.pi)\n",
    "            diff=[]\n",
    "            for i in range(len(pref_dir_o1_0)):\n",
    "                shift = np.concatenate([pref_dir_o1_0[i:],pref_dir_o1_0[:i]])\n",
    "                diff.append(shift-pref_dir_o5_0)\n",
    "            diff=np.concatenate(diff)\n",
    "            p_value_away_o = 1-np.sum(diff>0)/len(diff)\n",
    "            p_value_toward_o = 1-np.sum(diff<0)/len(diff)\n",
    "            pref_dir_c1_0 = np.abs(all_select[2][:,1]*180/np.pi - 0) \n",
    "            pref_dir_c5_0 = np.abs(all_select[3][:,1]*180/np.pi - 0)\n",
    "            diff=[]\n",
    "            for i in range(len(pref_dir_o1_0)):\n",
    "                shift = np.concatenate([pref_dir_c1_0[i:],pref_dir_c1_0[:i]])\n",
    "                diff.append(shift-pref_dir_c5_0)\n",
    "            diff=np.concatenate(diff)\n",
    "            p_value_away_c = 1-np.sum(diff>0)/len(diff)\n",
    "            p_value_toward_c = 1-np.sum(diff<0)/len(diff)\n",
    "            \n",
    "            print(i_neuron)\n",
    "            print(p_value_away_o)\n",
    "            print(p_value_away_c)\n",
    "    selectivity_info = pd.DataFrame(selectivity_info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>i_neuron</th>\n",
       "      <th>neuron_type</th>\n",
       "      <th>p_value</th>\n",
       "      <th>sample1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3960</td>\n",
       "      <td>muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3960</td>\n",
       "      <td>muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3960</td>\n",
       "      <td>muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3960</td>\n",
       "      <td>muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3961</td>\n",
       "      <td>goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3961</td>\n",
       "      <td>goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3961</td>\n",
       "      <td>goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3961</td>\n",
       "      <td>goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3962</td>\n",
       "      <td>muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3962</td>\n",
       "      <td>muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3962</td>\n",
       "      <td>muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3962</td>\n",
       "      <td>muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3963</td>\n",
       "      <td>goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3963</td>\n",
       "      <td>goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3963</td>\n",
       "      <td>goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3963</td>\n",
       "      <td>goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3964</td>\n",
       "      <td>muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3964</td>\n",
       "      <td>muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3964</td>\n",
       "      <td>muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-11-22_10-59-032022-11-28_10-23-272022-11-...</td>\n",
       "      <td>3964</td>\n",
       "      <td>muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 date  i_neuron  \\\n",
       "0   2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3960   \n",
       "1   2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3960   \n",
       "2   2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3960   \n",
       "3   2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3960   \n",
       "4   2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3961   \n",
       "5   2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3961   \n",
       "6   2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3961   \n",
       "7   2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3961   \n",
       "8   2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3962   \n",
       "9   2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3962   \n",
       "10  2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3962   \n",
       "11  2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3962   \n",
       "12  2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3963   \n",
       "13  2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3963   \n",
       "14  2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3963   \n",
       "15  2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3963   \n",
       "16  2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3964   \n",
       "17  2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3964   \n",
       "18  2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3964   \n",
       "19  2022-11-22_10-59-032022-11-28_10-23-272022-11-...      3964   \n",
       "\n",
       "                                          neuron_type  p_value  \\\n",
       "0   muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...      NaN   \n",
       "1   muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...      NaN   \n",
       "2   muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...      NaN   \n",
       "3   muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...      NaN   \n",
       "4   goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...      NaN   \n",
       "5   goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...      NaN   \n",
       "6   goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...      NaN   \n",
       "7   goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...      NaN   \n",
       "8   muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...      NaN   \n",
       "9   muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...      NaN   \n",
       "10  muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...      NaN   \n",
       "11  muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...      NaN   \n",
       "12  goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...      NaN   \n",
       "13  goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...      NaN   \n",
       "14  goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...      NaN   \n",
       "15  goodgoodgoodgoodgoodmuamuamuamuamuamuamuamuamu...      NaN   \n",
       "16  muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...      NaN   \n",
       "17  muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...      NaN   \n",
       "18  muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...      NaN   \n",
       "19  muagoodgoodgoodgoodmuamuamuamuamuamuamuamuamua...      NaN   \n",
       "\n",
       "                                              sample1  \n",
       "0   o1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "1   o5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "2   c1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "3   c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "4   o1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "5   o5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "6   c1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "7   c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "8   o1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "9   o5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "10  c1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "11  c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "12  o1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "13  o5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "14  c1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "15  c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "16  o1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "17  o5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "18  c1o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  \n",
       "19  c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5c1c5o1o5...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectivity_info1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EphysVibe-48n-7Gof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
